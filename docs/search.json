[
  {
    "objectID": "Tutorial.html",
    "href": "Tutorial.html",
    "title": "Getting Started",
    "section": "",
    "text": "Here is how you use our package:\nThis package has two different processes for getting the data. The first process is a polished dataset that can be used for the analysis functions. The second process uses an API key acquired from OpenAQ. Follow the link to follow the API functions to gather the most current and updated data for average air quality. The first process is a polished dataset that can be used for the analysis functions.\nNote: The functions that use the API require a large amount of processing time. The purpose of including these in the tutorial is to show the processes if recreation of the polished dataset is desired."
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "usadata is a Python package designed to support cleaning, analysis, and visualization of United States–related datasets. It is intended for students and analysts who want simple, reusable tools for working with U.S. demographic and statistical data.\nThis package provides: - Data cleaning tolls - Data analysis functions - Runnable streamlit app\n\n\n\nYou can install the required dependencies using:\nuv pip install -r requirements.txt\nTo install the package locally:\nuv pip install -e .\n\n\n\nUSAData/\n├── analysis.py # Data analysis functions\n├── cleaning.py # Data cleaning utilities\n├── streamlit_app.py # Streamlit application\n├── data/ # Included datasets\n└── __init__.py\n\n\n\n\n\nContains functions for preparing and cleaning raw datasets. Note there are several functions in this file that use an API to source and piece together the dataset. If the polished dataset is all that is needed use the code below to acquire a dataframe that sources data included in the package.\nExample usage:\nfrom usadata.cleaning import US\n\nclean_df = USdata()\n\n\n\nProvides functions for T-Tests and regression analysis.\nExample usage:\nfrom usadata.analysis import TTests\n\nTTests(clean_df)\n\n\n\nLaunches an interactive Streamlit dashboard for visualizing U.S. data.\nTo run the app:\nstreamlit run streamlit_app.py\n\n\n\n\nThe data/ directory in the src/usadata directory contains packaged datasets that are accessed internally using importlib.resources. These datasets are used in the functions that use the final polished dataset and also for sourcing some of the states data that requires excel files to merge the data.\n\n\n\nKey dependencies include: - pandas - streamlit - plotly - us - numpy - scipy - statsmodels - httpx - geopandas - requests\nSee requirements.txt for the full list.\n\n\n\n\n#| eval: false\nimport usaata\nfrom usadata.cleaning import USdata\nfrom usadata.analysis import TTests, regression analysis\n\nclean_df = USdata()\nTTests(clean_df)\nregression_analysis(clean_df)\n\n\n\nThis project is licensed under the MIT License.\n\n\n\nCreated by Rebekah Jensen and Noah Champagne as part of a course project.\n\n\n\nThis package was built using the modern Python packaging standard (pyproject.toml) and uv_build."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Python Package!",
    "section": "",
    "text": "Here is a website all about my package for STAT 386!\nDocumentation here.\nGet started here.\nReview the technical report."
  },
  {
    "objectID": "Documentation.html#overview",
    "href": "Documentation.html#overview",
    "title": "Documentation",
    "section": "",
    "text": "usadata is a Python package designed to support cleaning, analysis, and visualization of United States–related datasets. It is intended for students and analysts who want simple, reusable tools for working with U.S. demographic and statistical data.\nThis package provides: - Data cleaning tolls - Data analysis functions - Runnable streamlit app"
  },
  {
    "objectID": "Documentation.html#installation",
    "href": "Documentation.html#installation",
    "title": "Documentation",
    "section": "",
    "text": "You can install the required dependencies using:\nuv pip install -r requirements.txt\nTo install the package locally:\nuv pip install -e ."
  },
  {
    "objectID": "Documentation.html#package-structure",
    "href": "Documentation.html#package-structure",
    "title": "Documentation",
    "section": "",
    "text": "USAData/\n├── analysis.py # Data analysis functions\n├── cleaning.py # Data cleaning utilities\n├── streamlit_app.py # Streamlit application\n├── data/ # Included datasets\n└── __init__.py"
  },
  {
    "objectID": "Documentation.html#modules-and-functions",
    "href": "Documentation.html#modules-and-functions",
    "title": "Documentation",
    "section": "",
    "text": "Contains functions for preparing and cleaning raw datasets. Note there are several functions in this file that use an API to source and piece together the dataset. If the polished dataset is all that is needed use the code below to acquire a dataframe that sources data included in the package.\nExample usage:\nfrom usadata.cleaning import US\n\nclean_df = USdata()\n\n\n\nProvides functions for T-Tests and regression analysis.\nExample usage:\nfrom usadata.analysis import TTests\n\nTTests(clean_df)\n\n\n\nLaunches an interactive Streamlit dashboard for visualizing U.S. data.\nTo run the app:\nstreamlit run streamlit_app.py"
  },
  {
    "objectID": "Documentation.html#data",
    "href": "Documentation.html#data",
    "title": "Documentation",
    "section": "",
    "text": "The data/ directory in the src/usadata directory contains packaged datasets that are accessed internally using importlib.resources. These datasets are used in the functions that use the final polished dataset and also for sourcing some of the states data that requires excel files to merge the data."
  },
  {
    "objectID": "Documentation.html#dependencies",
    "href": "Documentation.html#dependencies",
    "title": "Documentation",
    "section": "",
    "text": "Key dependencies include: - pandas - streamlit - plotly - us - numpy - scipy - statsmodels - httpx - geopandas - requests\nSee requirements.txt for the full list."
  },
  {
    "objectID": "Documentation.html#example-workflow",
    "href": "Documentation.html#example-workflow",
    "title": "Documentation",
    "section": "",
    "text": "#| eval: false\nimport usaata\nfrom usadata.cleaning import USdata\nfrom usadata.analysis import TTests, regression analysis\n\nclean_df = USdata()\nTTests(clean_df)\nregression_analysis(clean_df)"
  },
  {
    "objectID": "Documentation.html#license",
    "href": "Documentation.html#license",
    "title": "Documentation",
    "section": "",
    "text": "This project is licensed under the MIT License."
  },
  {
    "objectID": "Documentation.html#authors",
    "href": "Documentation.html#authors",
    "title": "Documentation",
    "section": "",
    "text": "Created by Rebekah Jensen and Noah Champagne as part of a course project."
  },
  {
    "objectID": "Documentation.html#notes",
    "href": "Documentation.html#notes",
    "title": "Documentation",
    "section": "",
    "text": "This package was built using the modern Python packaging standard (pyproject.toml) and uv_build."
  },
  {
    "objectID": "TechnicalReport.html",
    "href": "TechnicalReport.html",
    "title": "Technical Report",
    "section": "",
    "text": "This project examines the relationship between air quality and various socio-economic and demographic indicators across U.S. states. These indicators include the percentage of adults aged 25 and older who did not complete high school, the Human Development Index assigned to each state, the number of people experiencing homelessness per 10,000 residents, the percentage of the homeless population that is unsheltered, and the Health, Education, and Income indices for each state.\nWe chose to measure air quality in terms of PM2.5, which refers to fine particulate matter with a diameter of 2.5 micrometers or less from sources like vehicles, factories, and wood burning. Values were averaged from a random sample of 20 air-quality sensors in each state."
  },
  {
    "objectID": "TechnicalReport.html#executive-summary",
    "href": "TechnicalReport.html#executive-summary",
    "title": "Technical Report",
    "section": "",
    "text": "This project examines the relationship between air quality and various socio-economic and demographic indicators across U.S. states. These indicators include the percentage of adults aged 25 and older who did not complete high school, the Human Development Index assigned to each state, the number of people experiencing homelessness per 10,000 residents, the percentage of the homeless population that is unsheltered, and the Health, Education, and Income indices for each state.\nWe chose to measure air quality in terms of PM2.5, which refers to fine particulate matter with a diameter of 2.5 micrometers or less from sources like vehicles, factories, and wood burning. Values were averaged from a random sample of 20 air-quality sensors in each state."
  },
  {
    "objectID": "TechnicalReport.html#project-context",
    "href": "TechnicalReport.html#project-context",
    "title": "Technical Report",
    "section": "Project Context",
    "text": "Project Context\nAir pollution is a critical public health concern, with PM2.5 being particularly harmful due to its ability to penetrate deep into the lungs and bloodstream. Understanding how and if air quality correlates with socio-economic factors such as education, income, and homelessness can help stakeholders such as public health agencies and policymakers prioritize resources and interventions.\nSuccess criteria for our project include creating a Python package that successfully cleans data from our sources and produces a final dataset that can be analyzed both visually and through descriptive statistics."
  },
  {
    "objectID": "TechnicalReport.html#data-sources",
    "href": "TechnicalReport.html#data-sources",
    "title": "Technical Report",
    "section": "Data Sources",
    "text": "Data Sources\n\nPrimary dataset: OpenAQ – Global air quality measurements, focusing on PM2.5 concentrations across U.S. states. Data was accessed via API.\nSupplementary data: Measure of America – Socio-economic indicators at the state level, including Human Development Index (HDI), Health Index, Education Index, Income Index, and homelessness statistics. Provided as Excel files."
  },
  {
    "objectID": "TechnicalReport.html#methodology",
    "href": "TechnicalReport.html#methodology",
    "title": "Technical Report",
    "section": "Methodology",
    "text": "Methodology\n\nData Acquisition\n\nWe collected PM2.5 data from OpenAQ using their API. Obtaining individual sensor data required multiple API requests. First, we queried the API to retrieve a list of U.S. locations. Using these locations, we then sent additional requests to obtain sensor-level measurements, filtering to include only sensors that recorded PM2.5 values. After removing missing (NaN) values, we grouped the data by state and selected a random sample of 20 PM2.5 sensors per state. For each sampled sensor, we calculated the most recent yearly average and used these values to estimate a state-level PM2.5 average.\nThe Measure of America datasets were freely downloadable in Excel format; however, we were required to provide contact information, describe our intended use of the data, and consent to using the data for non-commercial purposes only.\n\nCleaning pipeline\n\nData cleaning steps included handling missing values, standardizing column names, and converting data types. Measure of America did not provide a single consolidated Excel file; instead, separate files were used to report different indicators (e.g., education, environmental information, and the Human Development Index). To assemble the required variables, we combined multiple Excel files, resolved multi-level headers, and selected only the relevant fields.\nSimilarly, the OpenAQ data required merging multiple data frames obtained from separate API requests. These were consolidated into a final data frame containing one row per U.S. state and an estimated state-level PM2.5 value, which was then joined with the socio-economic data.\nThe main tools that we used throughout this cleaning process were the python libraries pandas and requests."
  },
  {
    "objectID": "TechnicalReport.html#results-diagnostics",
    "href": "TechnicalReport.html#results-diagnostics",
    "title": "Technical Report",
    "section": "Results & Diagnostics",
    "text": "Results & Diagnostics\nUsing our package, we performed several analyses on our data. The analyses and their results are outlined in the following sections.\n\nComparing Regions: Northern vs Southern States\nWe used a t-test to compare Northern and Southern states. The only variable showing a statistically significant regional difference is Health_Index. Other variables (air pollution, education, income, homelessness) do not differ significantly between North and Southern states.\n\n\n\nVariable\nt-statistic\np-value\n\n\n\n\nAvg_PM25\n-0.6254\n0.5377\n\n\nHealth_Index\n4.6735\n0.0001\n\n\nEducation_Index\n1.6863\n0.1055\n\n\nIncome_Index\n0.8212\n0.4191\n\n\nHomeless_Ratio\n-0.0878\n0.9310\n\n\n\n\n\nComparing Regions: East vs West States\nLooking at Eastern vs Western states, there is a significant difference in both education and health indices, but none of the other socioeconomic measures.\n\n\n\nVariable\nt-statistic\np-value\n\n\n\n\nAvg_PM25\n0.0927\n0.9268\n\n\nHealth_Index\n-2.3041\n0.0257\n\n\nEducation_Index\n2.2673\n0.0279\n\n\nIncome_Index\n1.4959\n0.1413\n\n\nHomeless_Ratio\n-0.7737\n0.4428"
  },
  {
    "objectID": "TechnicalReport.html#discussion-next-steps",
    "href": "TechnicalReport.html#discussion-next-steps",
    "title": "Technical Report",
    "section": "Discussion & Next Steps",
    "text": "Discussion & Next Steps\nOur analysis aimed to identify key state-level factors associated with average PM2.5 levels across the U.S. using an Ordinary Least Squares (OLS) regression model. The overall model only explained a small portion (13.5%) of the differences in PM2.5 between states, indicating that most of the variation is driven by other factors not included in this analysis, such as local industry, geography, or specific air quality regulations.\nThe choropleth map on our Streamlit app shows the geographical spread of PM2.5 values, highlighting state-to-state variation. Notably, the map shows that Virginia has a high PM2.5 value, which appears to be an outlier that could be influencing the regression results.\nThe correlation matrix reveals some interesting relationships. Unfortunately, the average PM2.5 value for each state only has a weak positive correlation with the percentage of adults who did not graduate high school, and an almost nonexistent correlation with the other variables, including the Health, Education, and Income indices.\nAs expected, the Human Development Index (HDI) is highly correlated with its constituent parts—Health, Education, and Income indices. There are, however, to suprising observations. First, there is a moderate positive correlation (+0.53) between the Homeless Ratio and the HDI, which seems counter-intuitive and may be worth further investigation. The correlation matrix also shows a weak linear relationship between the percentage of electricity generated by coal and natural gas and the average PM2.5 levels, which we expected would have a relationship.\n\nLimitations\n\nMulticollinearity: The OLS model and the correlation matrix indicated that there was multicollinearity—several predictor variables are highly correlated with each other. This makes it difficult to isolate the unique effect of any single predictor.\nOutlier Influence: The presence of a likely outlier (one of Virginia’s sensors) may be distorting the fit of the model and the coefficient values.\n\n\n\nFuture Experiments and Open Questions\nTo build a more robust predictive model, future analysis should consider the following steps:\n\nAddress Outliers: Run the model again after removing the outlier sensor in Virginia to see if anything changes.\nExplore Different Predictors: Given the model’s low R², additional variables should be investigated, such as state-level air quality regulations, population density, or local industry composition (e.g., manufacturing vs. service)."
  },
  {
    "objectID": "Tutorial.html#immediate-access-to-clean-dataset",
    "href": "Tutorial.html#immediate-access-to-clean-dataset",
    "title": "Getting Started",
    "section": "Immediate Access to Clean Dataset",
    "text": "Immediate Access to Clean Dataset\nThe following function will return the clean polished dataset as a dataframe without having to go through the API form OpenAQ:\n\nfrom usadata import cleaning as US\n\ndata = US.USdata()"
  },
  {
    "objectID": "Tutorial.html#using-api-functions",
    "href": "Tutorial.html#using-api-functions",
    "title": "Getting Started",
    "section": "Using API Functions",
    "text": "Using API Functions\nIt is important you follow the steps below in order to achieve the same dataset the USdata function outputs. Warning!!! Processing time is large due to API limits.\n\nUS Locations\nThe first step to acquiring the data necessary for the polished set is getting all locations of sensors in the USA. Using the following function will give you a dataframe of all US sensors.\n\nfrom usadata import cleaning as US\n\nKEY = YOUR_API_KEY\n\nsensor_locations = US.get_locations(KEY)\n\n\n\nSample Locations\nThe amount of sensors is a large amount of data, in order cut down on the amount of locations and time for requesting from the API, the following function samples 25 locations from each state.\nUse the dataframe created from the US location function to pass into the sample function.\n\nfrom usadata import cleaning as US\n\nsampled_locations = US.sample_location(sensor_locations)\n\n\n\nSensor IDs\nUsing the sampled locations dataframe the following function gets the sensor IDs for the measurement PM 2.5 from the API.\nPass in the sampled locations dataframe from the previous function.\n\nfrom usadata import cleaning as US\n\nKEY = YOUR_API_KEY\n\nsensor_id = get_sensorID(sampled_locations, KEY)\n\n\n\nAverage PM 2.5\nUsing the dataframe acquired from the previous function the following function gathers the average of the sensors lifetime from the API. This function will return a result to an existing .CSV file. You must have an output .CSV file declared.\nPass in the resulting dataframe from the previous function into the first argument.\n\nfrom usadata import cleaning as US\n\nKEY = YOUR_API_KEY\n\nOUTPUT_CSV = \"Your_csv_file.csv\"\n\nfetch_averages(sensor_ids, OUTPUT_CSV, KEY)"
  },
  {
    "objectID": "Tutorial.html#united-states-statistics",
    "href": "Tutorial.html#united-states-statistics",
    "title": "Getting Started",
    "section": "United States Statistics",
    "text": "United States Statistics\nThe polished dataset results in 50 data points each corresponding to a state. The following function will melt several excel files given in the package for you to melt and consolidate with the air quality data gathered from the API.\nThe following function returns the result from the melted excel files.\n\nfrom usadata import cleaning as US\n\nState_Data = US.state_info()\n\nThe last step to creating the dataset is merging the two dataframes collected in this process. Note this function can only pass dataframes, be sure to read in you sensor averages using Pandas before passing to the function.\nThis function takes the average of the averages gathered for each state then maps it to the states in the states data created from merging the excel files.\n\nfrom usadata import cleaning as US\nimport pandas as pd\n\nSensor_Averages = pd.read\n\ncleaned_data = US.merge_data(Sensor_Averages, State_Data)"
  },
  {
    "objectID": "Tutorial.html#t-test",
    "href": "Tutorial.html#t-test",
    "title": "Getting Started",
    "section": "T-Test",
    "text": "T-Test\nThe T-Test function test if there is significant differences between north and south regions of the US as well as east and west regions. The T-Test prints the region, the variable tested, the test statistic, and p-value.\n\nfrom usadata import analysis as US\n\ndata = US.USdata()\n\nUS.TTests(data)"
  },
  {
    "objectID": "Tutorial.html#multiple-linear-regression",
    "href": "Tutorial.html#multiple-linear-regression",
    "title": "Getting Started",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nThe regression function takes in the dataset and the desired response variable. The function will run a best subsets to choose significant predictors using AIC measurement. The best fit model found using best subsets will print a summary output of the model.\nNOTE: The response variable must be a string input and correspond to a column name in the USdata data.\n\nfrom usadata import analysis as US\n\nresponse = \"Avg_PM25\"\n\ndata = US.USdata()\n\nUS.regression_analysis(data, response)"
  },
  {
    "objectID": "TechnicalReport.html#best-ols-model-for-average-pm-2.5",
    "href": "TechnicalReport.html#best-ols-model-for-average-pm-2.5",
    "title": "Technical Report",
    "section": "Best OLS Model for Average PM 2.5",
    "text": "Best OLS Model for Average PM 2.5\nPredictors: Not Graduated, HDI, Homeless Ratio\nThe best Ordinary Least Squares (OLS) model for predicting average PM2.5 levels looked at three state-level factors: the percentage of people age 25 and over who did not graduate from high school, the Human Development Index (HDI), and the homelessness ratio. The model explains only a small part of the differences in PM2.5 between states. Of the three factors, not graduating and homelessness were significant predictors: states with more people who did not graduate tended to have higher PM2.5, while states with higher homelessness had slightly lower PM2.5. HDI showed a small positive effect, but it was not strong enough to be considered statistically significant. The model also suggests that the predictors themselves might be closely related (multicollinearity), which can make the specific size of the effects a little less certain. Some tests suggest that the data is a bit uneven (the errors are not normally distributed), so the results should be interpreted with caution.\n\nModel Fit Statistics\n\n\n\nMetric\nValue\n\n\n\n\nNumber of observations\n51\n\n\nR-squared\n0.135\n\n\nAdjusted R-squared\n0.080\n\n\nF-statistic\n2.446\n\n\nProb (F-statistic)\n0.0755\n\n\nLog-Likelihood\n-138.30\n\n\nAIC\n284.6\n\n\nBIC\n292.3\n\n\nDurbin–Watson\n1.922\n\n\n\n\n\nRegression Coefficients\n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\nt-statistic\np-value\n95% CI\n\n\n\n\nIntercept\n-4.7427\n6.893\n-0.688\n0.495\n[-18.609, 9.124]\n\n\nNot_graduated\n0.4467\n0.216\n2.065\n0.044\n[0.012, 0.882]\n\n\nHDI\n2.0516\n1.115\n1.840\n0.072\n[-0.191, 4.295]\n\n\nHomeless_Ratio\n-0.0818\n0.039\n-2.086\n0.042\n[-0.161, -0.003]\n\n\n\n\n\nModel Diagnostics\n\n\n\nTest\nStatistic\np-value\n\n\n\n\nOmnibus\n37.476\n0.000\n\n\nJarque–Bera\n108.202\n3.19e-24\n\n\nSkewness\n2.040\n—\n\n\nKurtosis\n8.855\n—\n\n\nCondition Number\n337\n—"
  }
]